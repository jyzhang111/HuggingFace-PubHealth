{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HuggingFace-PubHealth.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "a222abaa01cf442c94914cf5bf112ac8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_02d75eacb84a48cd85b3ff53d0c261e8",
              "IPY_MODEL_8361bc6d7c57470e8bb637f464075a88",
              "IPY_MODEL_4d805f34a5524a08aef40bc3556a848a"
            ],
            "layout": "IPY_MODEL_6761cda87b1440309ee4920561111b8a"
          }
        },
        "02d75eacb84a48cd85b3ff53d0c261e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_66e1c033b81c454aa68239a079489531",
            "placeholder": "​",
            "style": "IPY_MODEL_36be3b424da84ee1b8992c9f5d34bd42",
            "value": "100%"
          }
        },
        "8361bc6d7c57470e8bb637f464075a88": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b5d7ff0ab39b4c81ac4bb3ddeedfe6f8",
            "max": 3,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_70a9aadeacb9448e880d68c949c9c74b",
            "value": 3
          }
        },
        "4d805f34a5524a08aef40bc3556a848a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_adecfe899e194206a42641b9bd444826",
            "placeholder": "​",
            "style": "IPY_MODEL_86a45826b6324cca835e4e61c9fe668d",
            "value": " 3/3 [00:00&lt;00:00, 73.38it/s]"
          }
        },
        "6761cda87b1440309ee4920561111b8a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "66e1c033b81c454aa68239a079489531": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "36be3b424da84ee1b8992c9f5d34bd42": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b5d7ff0ab39b4c81ac4bb3ddeedfe6f8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "70a9aadeacb9448e880d68c949c9c74b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "adecfe899e194206a42641b9bd444826": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "86a45826b6324cca835e4e61c9fe668d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "305f0e5f47364df9a3090f984e81f25f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_88e4de8ab59e4209b408d9d101b4d7c9",
              "IPY_MODEL_d473f6645b874da5921ed8846fb2ad60",
              "IPY_MODEL_511b00eb57c04733bd4ab47a9caf533c"
            ],
            "layout": "IPY_MODEL_0b7f8bd2333b42a1bf142a0b4ac9603a"
          }
        },
        "88e4de8ab59e4209b408d9d101b4d7c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6fd967b209af4b60a2e6babd0018d2c0",
            "placeholder": "​",
            "style": "IPY_MODEL_630dc44e618d4e0abae0c97f521c7214",
            "value": "100%"
          }
        },
        "d473f6645b874da5921ed8846fb2ad60": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d26f49db38d3479ea312f7dd687f32b8",
            "max": 12260,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8b177e4ef5354ce2a15859798f7427fe",
            "value": 12260
          }
        },
        "511b00eb57c04733bd4ab47a9caf533c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_389cf0dc692549579bce4bb08c32c085",
            "placeholder": "​",
            "style": "IPY_MODEL_5b66ea9f47714b08b8bed5ba9933a617",
            "value": " 12260/12260 [4:05:50&lt;00:00,  1.44it/s]"
          }
        },
        "0b7f8bd2333b42a1bf142a0b4ac9603a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6fd967b209af4b60a2e6babd0018d2c0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "630dc44e618d4e0abae0c97f521c7214": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d26f49db38d3479ea312f7dd687f32b8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8b177e4ef5354ce2a15859798f7427fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "389cf0dc692549579bce4bb08c32c085": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5b66ea9f47714b08b8bed5ba9933a617": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b61110fde821414ab2a7e7006bb79af5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a457180b6f794b05b82ac4eee08b6266",
              "IPY_MODEL_b6eac0380a1642d6a1155e2049afaf65",
              "IPY_MODEL_486d05a3393c441e93812e9df66426bc"
            ],
            "layout": "IPY_MODEL_e4d360fd240e4787ad9564f2bb534266"
          }
        },
        "a457180b6f794b05b82ac4eee08b6266": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8ab924dcc54c4de3bd15c4a01e37a8bd",
            "placeholder": "​",
            "style": "IPY_MODEL_01af59788ee54e7bbfc125f7855b95ac",
            "value": " 99%"
          }
        },
        "b6eac0380a1642d6a1155e2049afaf65": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b12cf33319dc4bc7b768eaf8b918700b",
            "max": 155,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5537434fa14c43c6be9bb6d102071c8a",
            "value": 154
          }
        },
        "486d05a3393c441e93812e9df66426bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_39d17796f24047eaaecc3597f645ca05",
            "placeholder": "​",
            "style": "IPY_MODEL_03248e314a1942a88c0d5c19c58b7c6d",
            "value": " 154/155 [00:48&lt;00:00,  3.47it/s]"
          }
        },
        "e4d360fd240e4787ad9564f2bb534266": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8ab924dcc54c4de3bd15c4a01e37a8bd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "01af59788ee54e7bbfc125f7855b95ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b12cf33319dc4bc7b768eaf8b918700b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5537434fa14c43c6be9bb6d102071c8a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "39d17796f24047eaaecc3597f645ca05": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "03248e314a1942a88c0d5c19c58b7c6d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Model Design\n",
        "\n",
        "My model will be a RoBERTa-based model from the Huggingface Transformer library. The architecture is as follows:\n",
        "1. Fine-tune a RoBERTa model on the claim and explanation fields\n",
        "2. Use an AdamW optimizer to update the weights\n",
        "3. Run for 10 epochs with a batch size of 8"
      ],
      "metadata": {
        "id": "Rhy0OMPDPAmV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "DI4D2PO4jtw3"
      },
      "outputs": [],
      "source": [
        "# Installations\n",
        "!pip3 install datasets --quiet\n",
        "!pip3 install transformers --quiet\n",
        "from IPython import display # for limiting some display sizes"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset load and inspection"
      ],
      "metadata": {
        "id": "gW1flj6ZsqHK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import list_datasets, load_dataset, Value, ClassLabel\n",
        "\n",
        "LABEL_DICTIONARY = {0: 'false', 1: 'mixture', 2: 'true', 3: 'unproven'}\n",
        "\n",
        "dataset = load_dataset('health_fact', 'binary')\n",
        "print(dataset.keys())\n",
        "for k in dataset.keys():\n",
        "    new_id = list(range(len(dataset[k])))\n",
        "    dataset[k].add_column('new_id', new_id)\n",
        "print(dataset['train'].features)\n",
        "print(dataset['test'].features)\n",
        "print('\\n')\n",
        "dataset['test'][0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 347,
          "referenced_widgets": [
            "a222abaa01cf442c94914cf5bf112ac8",
            "02d75eacb84a48cd85b3ff53d0c261e8",
            "8361bc6d7c57470e8bb637f464075a88",
            "4d805f34a5524a08aef40bc3556a848a",
            "6761cda87b1440309ee4920561111b8a",
            "66e1c033b81c454aa68239a079489531",
            "36be3b424da84ee1b8992c9f5d34bd42",
            "b5d7ff0ab39b4c81ac4bb3ddeedfe6f8",
            "70a9aadeacb9448e880d68c949c9c74b",
            "adecfe899e194206a42641b9bd444826",
            "86a45826b6324cca835e4e61c9fe668d"
          ]
        },
        "id": "84w1DqZ9kXMB",
        "outputId": "144cc98d-7b91-4a29-cefd-8dcd4c125c3a"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using custom data configuration binary\n",
            "Reusing dataset health_fact (/root/.cache/huggingface/datasets/health_fact/binary/1.1.0/99503637e4255bd805f84d57031c18fe4dd88298f00299d56c94fc59ed68ec19)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/3 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a222abaa01cf442c94914cf5bf112ac8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dict_keys(['train', 'test', 'validation'])\n",
            "{'claim_id': Value(dtype='string', id=None), 'claim': Value(dtype='string', id=None), 'date_published': Value(dtype='string', id=None), 'explanation': Value(dtype='string', id=None), 'fact_checkers': Value(dtype='string', id=None), 'main_text': Value(dtype='string', id=None), 'sources': Value(dtype='string', id=None), 'label': ClassLabel(num_classes=4, names=['false', 'mixture', 'true', 'unproven'], id=None), 'subjects': Value(dtype='string', id=None)}\n",
            "{'claim_id': Value(dtype='string', id=None), 'claim': Value(dtype='string', id=None), 'date_published': Value(dtype='string', id=None), 'explanation': Value(dtype='string', id=None), 'fact_checkers': Value(dtype='string', id=None), 'main_text': Value(dtype='string', id=None), 'sources': Value(dtype='string', id=None), 'label': ClassLabel(num_classes=4, names=['false', 'mixture', 'true', 'unproven'], id=None), 'subjects': Value(dtype='string', id=None)}\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'claim': 'A mother revealed to her child in a letter after her death that she had just one eye because she had donated the other to him.',\n",
              " 'claim_id': '33456',\n",
              " 'date_published': 'November 6, 2011',\n",
              " 'explanation': 'The one-eyed mother story expounds upon two moral messages: the unconditional, all-encompassing love we expect mothers to always feel for their children, and the admonition to not put off cherishing loved ones and appreciating their sacrifices while they’re still around.',\n",
              " 'fact_checkers': 'David Mikkelson',\n",
              " 'label': 0,\n",
              " 'main_text': \"In April 2005, we spotted a tearjerker on the Internet about a mother who gave up one of her eyes to a son who had lost one of his at an early age. By February 2007 the item was circulating in e-mail in the following shortened version:  My mom only had one eye. I hated her… She was such an embarrassment. She cooked for students and teachers to support the family. There was this one day during elementary school where my mom came to say hello to me. I was so embarrassed. How could she do this to me? I ignored her, threw her a hateful look and ran out. The next day at school one of my classmates said, “EEEE, your mom only has one eye!” I wanted to bury myself. I also wanted my mom to just disappear. I confronted her that day and said, “If you’re only gonna make me a laughing stock, why don’t you just die?” My mom did not respond… I didn’t even stop to think for a second about what I had said, because I was full of anger. I was oblivious to her feelings. I wanted out of that house, and have nothing to do with her. So I studied real hard, got a chance to go abroad to study. Then, I got married. I bought a house of my own. I had kids of my own. I was happy with my life, my kids and the comforts. Then one day, my Mother came to visit me. She hadn’t seen me in years and she didn’t even meet her grandchildren. When she stood by the door, my children laughed at her, and I yelled at her for coming over uninvited. I screamed at her, “How dare you come to my house and scare my children! GET OUT OF HERE! NOW!! !” And to this, my mother quietly answered, “Oh, I’m so sorry. I may have gotten the wrong address,” and she disappeared out of sight. One day, a letter regarding a school reunion came to my house. So I lied to my wife that I was going on a business trip. After the reunion, I went to the old shack just out of curiosity. My neighbors said that she died. I did not shed a single tear. They handed me a letter that she had wanted me to have. My dearest son, I think of you all the time. I’m sorry that I came to your house and scared your children. I was so glad when I heard you were coming for the reunion. But I may not be able to even get out of bed to see you. I’m sorry that I was a constant embarrassment to you when you were growing up. You see……..when you were very little, you got into an accident, and lost your eye. As a mother, I couldn’t stand watching you having to grow up with one eye. So I gave you mine. I was so proud of my son who was seeing a whole new world for me, in my place, with that eye. With all my love to you, Your mother. In its earlier incarnation, the story identified by implication its location as Korea through statements made by both the mother and the son (the son’s “I left my mother and came to Seoul” and the mother’s “I won’t visit Seoul anymore”). It also supplied a reason for the son’s behavior when his mother arrived unexpectedly to visit him (“My little girl ran away, scared of my mom’s eye” and “I screamed at her, ‘How dare you come to my house and scare my daughter!'”). A further twist was provided in the original: rather than gaining the news of his mother’s death from neighbors (who hand him her letter), the son instead discovered the woman who bore him lying dead on the floor of what used to be his childhood home, her missive to him clutched in her lifeless hand: Give your parents roses while they are alive, not deadMY mom only had one eye. I hated her … she was such an embarrassment. My mom ran a small shop at a flea market. She collected little weeds and such to sell … anything for the money we needed she was such an embarrassment. There was this one day during elementary school … It was field day, and my mom came. I was so embarrassed. How could she do this to me? I threw her a hateful look and ran out. The next day at school … “your mom only has one eye?!? !” … And they taunted me. I wished that my mom would just disappear from this world so I said to my mom, “mom … Why don’t you have the other eye?! If you’re only going to make me a laughingstock, why don’t you just die?!! !” my mom did not respond … I guess I felt a little bad, but at the same time, it felt good to think that I had said what I’d wanted to say all this time… maybe it was because my mom hadn’t punished me, but I didn’t think that I had hurt her feelings very badly. That night… I woke up, and went to the kitchen to get a glass of water. My mom was crying there, so quietly, as if she was afraid that she might wake me. I took a look at her, and then turned away. Because of the thing I had said to her earlier, there was something pinching at me in the corner of my heart. Even so, I hated my mother who was crying out of her one eye. So I told myself that I would grow up and become successful. Because I hated my one-eyed mom and our desperate poverty… then I studied real hard. I left my mother and came to Seoul and studied, and got accepted in the Seoul University with all the confidence I had. Then, I got married. I bought a house of my own. Then I had kids, too… now I’m living happily as a successful man. I like it here because it’s a place that doesn’t remind me of my mom. This happiness was getting bigger and bigger, when… what?! Who’s this…it was my mother… still with her one eye. It felt as if the whole sky was falling apart on me. My little girl ran away, scared of my mom’s eye. And I asked her, “who are you? !” “I don’t know you!! !” as if trying to make that real. I screamed at her, “How dare you come to my house and scare my daughter!” “GET OUT OF HERE! NOW!! !” and to this, my mother quietly answered, “oh, I’m so sorry. I may have gotten the wrong address,” and she disappeared out of sight. Thank goodness… she doesn’t recognize me… I was quite relieved. I told myself that I wasn’t going to care, or think about this for the rest of my life. Then a wave of relief came upon me… One day, a letter regarding a school reunion came to my house. So, lying to my wife that I was going on a business trip, I went. After the reunion, I went down to the old shack, that I used to call a house… just out of curiosity there, I found my mother fallen on the cold ground. But I did not shed a single tear. She had a piece of paper in her hand…. it was a letter to me. My son… I think my life has been long enough now… And… I won’t visit Seoul anymore… but would it be too much to ask if I wanted you to come visit me once in a while? I miss you so much… and I was so glad when I heard you were coming for the reunion. But I decided not to go to the school. …for you… and I’m sorry that I only have one eye, and I was an embarrassment for you. You see, when you were very little, you got into an accident, and lost your eye. as a mom, I couldn’t stand watching you having to grow up with only one eye… so I gave you mine… I was so proud of my son that was seeing a whole new world for me, in my place, with that eye. I was never upset at you for anything you did… the couple times that you were angry with me, I thought to myself, ‘it’s because he loves me…’ my son. Oh, my son… I don’t want you to cry for me, because of my death. My son, I love you my son, I love you so much. With all modern medical technology, transplantation of the eyeball is still impossible. The optic nerve isn’t an ordinary nerve, but instead an inset running from the brain. Modern medicine isn’t able to “connect” an eyeball back to brain after an optic nerve has been severed, let alone transplant the eye from a different person. (The only exception is the cornea, the transparent part in front of the eye: corneas are transplanted to replace injured and opaque ones.) We won’t try to comment on whether any surgeon would accept an eye from a living donor for transplant into another — we’ll leave that to others who are far more knowledgeable about medical ethics and transplant procedures. But we will note that the plot device of a mother’s dramatic sacrifice for the sake of her child’s being revealed in a written communication delivered after her demise appears in another legend about maternal love: the 2008 tale about a woman who left a touching message on her cell phone even as life ebbed from her as she used her body to shield the tot during an earthquake. Giving up one’s own life for a loved one is central to a 2005 urban legend about a boy on a motorcycle who has his girlfriend hug him one last time and put on his helmet just before the crash that kills him and spares her. Returning to the “notes from the dead” theme is the 1995 story about a son who discovers only through a posthumous letter from his mother what their occasional dinner “dates” had meant to her. Another legend we’re familiar with features a meme used in the one-eyed mother story (the coming to light of the enduring love of the person who died for the completely unworthy person she’d lavished it on), but that one involves a terminally ill woman and her cheating husband. In it, an about-to-be-spurned wife begs the adulterous hoon she’d married to stick around for another 30 days and to carry her over the threshold of their home once every day of that month as her way of keeping him around long enough for her to kick the bucket and thus spare their son the knowledge that his parents were on the verge of divorce.\",\n",
              " 'sources': ' ',\n",
              " 'subjects': 'Glurge Gallery'}"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Upon further inspection we can find some peculiarities in the labels of this dataset:"
      ],
      "metadata": {
        "id": "ZRUrvPL8wLfK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "label_dict = {-1:0, 0: 0, 1: 0, 2: 0, 3: 0}\n",
        "count = 0\n",
        "for i in list(dataset['train']['label']):\n",
        "    label_dict[i] += 1\n",
        "    if i == -1: print(count, end =\" \")\n",
        "    count += 1\n",
        "print()\n",
        "\n",
        "val_label_dict = {-1:0, 0: 0, 1: 0, 2: 0, 3: 0}\n",
        "for i in list(dataset['validation']['label']):\n",
        "    val_label_dict[i] += 1\n",
        "\n",
        "test_label_dict = {-1:0, 0: 0, 1: 0, 2: 0, 3: 0}\n",
        "for i in list(dataset['test']['label']):\n",
        "    test_label_dict[i] += 1\n",
        "\n",
        "print(label_dict)\n",
        "print(val_label_dict)\n",
        "print(test_label_dict)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VGjc2MZxwRIU",
        "outputId": "3a6010e2-256b-4608-ce45-cbf36f261a0b"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1312 1313 1314 2151 2152 2478 2479 2480 2650 2651 2652 5259 5260 5261 5489 5490 5491 6053 6054 6055 6216 6217 6218 6654 6655 8506 8507 8508 \n",
            "{-1: 28, 0: 3001, 1: 1434, 2: 5078, 3: 291}\n",
            "{-1: 11, 0: 380, 1: 164, 2: 629, 3: 41}\n",
            "{-1: 2, 0: 388, 1: 201, 2: 599, 3: 45}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the below, the -1 labels have one thing that seem to be consistent among them: they do not correspond to an actual medical claim. It seems to be more about logistics, or the information is missing altogether. As they represent a small part of the dataset we remove these labels."
      ],
      "metadata": {
        "id": "kOc48RIrpaU4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(dataset['train']['claim'][1312:1315])\n",
        "print(dataset['train']['explanation'][1312:1315])\n",
        "\n",
        "# Filter the dataset to keep only the labels that make sense\n",
        "dataset = dataset.filter(lambda example: example['label'] > -0.5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4xV-eMPAZHCx",
        "outputId": "29e3ed38-4ccc-427c-b651-c455ee583e27"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loading cached processed dataset at /root/.cache/huggingface/datasets/health_fact/binary/1.1.0/99503637e4255bd805f84d57031c18fe4dd88298f00299d56c94fc59ed68ec19/cache-4f9558a30922a2c4.arrow\n",
            "Loading cached processed dataset at /root/.cache/huggingface/datasets/health_fact/binary/1.1.0/99503637e4255bd805f84d57031c18fe4dd88298f00299d56c94fc59ed68ec19/cache-29b1405e3085ad2c.arrow\n",
            "Loading cached processed dataset at /root/.cache/huggingface/datasets/health_fact/binary/1.1.0/99503637e4255bd805f84d57031c18fe4dd88298f00299d56c94fc59ed68ec19/cache-7f4c8737cf0a5f22.arrow\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[' A forwarded email that cautions veterans about   questions that maybe asked while in treatment at the Veterans Hospital.\\xa0 The email says that   if a veteran is asked about being stressed, feeling threatened or   wanting to harm someone and if their answer is yes they could lose any   authorization to carry a concealed weapon.\\xa0 A warning to those to   expect healthcare workers to ask, “Do you have a gun in your house.” \\xa0       ', '', 'This one is fiction. A   spokesperson at the Veterans Hospital told TruthorFiction.com that all patients are protected by doctor/patient   confidentiality and any information taken by the Veterans Administration   (VA) is never shared with any outside agencies. The only   exemption to the case would be if a hospital were asked to assist in a   criminal investigation. The three questions about feeling   stressed, threatened and desiring to harm others are to test for Post   Traumatic Stress Disorder (PTSD) which some of our men and women in the   armed services have suffered as a result of combat. This test is administered   to many patients who served in the Gulf War, Afghanistan and Iraq. Other versions of this eRumor say that Medicare patients are being asked   these questions by the health providers. We have not found   any evidence of this being true either. Posted 05/18/09\\xa0 Updated   02/10/14    Comments']\n",
            "['Veterans can lose their weapons permit if they answer yes to three questions in a medical exam', '', 'false']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load Roberta Tokenizer and Model, and prepare dataset for PyTorch"
      ],
      "metadata": {
        "id": "S73quPol7q-g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "from torch.utils.data import DataLoader\n",
        "import torch\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained('roberta-base')\n",
        "model = AutoModelForSequenceClassification.from_pretrained('roberta-base', num_labels=4)\n",
        "\n",
        "def tokenize_function(batch):\n",
        "    encoded = tokenizer(batch[\"claim\"], batch[\"explanation\"], padding=\"max_length\", truncation=True, max_length=512)\n",
        "    return encoded\n",
        "\n",
        "tokenized_dataset = dataset.map(tokenize_function, batched=True)\n",
        "tokenized_dataset = tokenized_dataset.remove_columns([\"claim_id\", \"date_published\", \"fact_checkers\", \"main_text\", \"sources\", \"subjects\"])\n",
        "tokenized_dataset = tokenized_dataset.remove_columns([\"claim\", \"explanation\"])\n",
        "tokenized_dataset = tokenized_dataset.rename_column(\"label\", \"labels\")\n",
        "tokenized_dataset.set_format(\"torch\")\n",
        "print(tokenized_dataset['train'].features)\n",
        "\n",
        "# Use DataLoader for batched input to PyTorch\n",
        "batch_size = 8\n",
        "train_dataloader = DataLoader(tokenized_dataset['train'], shuffle=True, batch_size=batch_size)\n",
        "val_dataloader = DataLoader(tokenized_dataset['validation'], shuffle=True, batch_size=batch_size)\n",
        "test_dataloader = DataLoader(tokenized_dataset['test'], shuffle=True, batch_size=batch_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6UD4xCg0r3Xc",
        "outputId": "280e421e-2025-4e3d-ac35-5b75ee026fa4"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.dense.weight', 'roberta.pooler.dense.weight', 'roberta.pooler.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.bias']\n",
            "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.out_proj.bias', 'classifier.dense.bias', 'classifier.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Loading cached processed dataset at /root/.cache/huggingface/datasets/health_fact/binary/1.1.0/99503637e4255bd805f84d57031c18fe4dd88298f00299d56c94fc59ed68ec19/cache-54e1c1c982099306.arrow\n",
            "Loading cached processed dataset at /root/.cache/huggingface/datasets/health_fact/binary/1.1.0/99503637e4255bd805f84d57031c18fe4dd88298f00299d56c94fc59ed68ec19/cache-6f2820005a9b74fb.arrow\n",
            "Loading cached processed dataset at /root/.cache/huggingface/datasets/health_fact/binary/1.1.0/99503637e4255bd805f84d57031c18fe4dd88298f00299d56c94fc59ed68ec19/cache-a2d64521b886b59e.arrow\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'labels': ClassLabel(num_classes=4, names=['false', 'mixture', 'true', 'unproven'], id=None), 'input_ids': Sequence(feature=Value(dtype='int32', id=None), length=-1, id=None), 'attention_mask': Sequence(feature=Value(dtype='int8', id=None), length=-1, id=None)}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Setting up optimizers and training the model"
      ],
      "metadata": {
        "id": "4v-wCNiT_RgH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AdamW\n",
        "from transformers import get_scheduler\n",
        "\n",
        "# Optimizer and schedules for optimizer\n",
        "optimizer = AdamW(model.parameters(), lr=5e-5)\n",
        "\n",
        "num_epochs = 10\n",
        "num_training_steps = num_epochs * len(train_dataloader)\n",
        "lr_scheduler = get_scheduler(\n",
        "    name=\"linear\", optimizer=optimizer, num_warmup_steps=0, num_training_steps=num_training_steps\n",
        ")\n",
        "\n",
        "# Setup GPU\n",
        "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "print(model.to(device))\n",
        "display.Javascript(\"google.colab.output.setIframeHeight('300px');\") # limit the display size"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "2QaoWNuj_RMY",
        "outputId": "950918ed-586a-41fe-a9ce-74072cde5b41"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RobertaForSequenceClassification(\n",
            "  (roberta): RobertaModel(\n",
            "    (embeddings): RobertaEmbeddings(\n",
            "      (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
            "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
            "      (token_type_embeddings): Embedding(1, 768)\n",
            "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "      (dropout): Dropout(p=0.1, inplace=False)\n",
            "    )\n",
            "    (encoder): RobertaEncoder(\n",
            "      (layer): ModuleList(\n",
            "        (0): RobertaLayer(\n",
            "          (attention): RobertaAttention(\n",
            "            (self): RobertaSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): RobertaSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): RobertaIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            (intermediate_act_fn): GELUActivation()\n",
            "          )\n",
            "          (output): RobertaOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (1): RobertaLayer(\n",
            "          (attention): RobertaAttention(\n",
            "            (self): RobertaSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): RobertaSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): RobertaIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            (intermediate_act_fn): GELUActivation()\n",
            "          )\n",
            "          (output): RobertaOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (2): RobertaLayer(\n",
            "          (attention): RobertaAttention(\n",
            "            (self): RobertaSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): RobertaSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): RobertaIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            (intermediate_act_fn): GELUActivation()\n",
            "          )\n",
            "          (output): RobertaOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (3): RobertaLayer(\n",
            "          (attention): RobertaAttention(\n",
            "            (self): RobertaSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): RobertaSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): RobertaIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            (intermediate_act_fn): GELUActivation()\n",
            "          )\n",
            "          (output): RobertaOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (4): RobertaLayer(\n",
            "          (attention): RobertaAttention(\n",
            "            (self): RobertaSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): RobertaSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): RobertaIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            (intermediate_act_fn): GELUActivation()\n",
            "          )\n",
            "          (output): RobertaOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (5): RobertaLayer(\n",
            "          (attention): RobertaAttention(\n",
            "            (self): RobertaSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): RobertaSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): RobertaIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            (intermediate_act_fn): GELUActivation()\n",
            "          )\n",
            "          (output): RobertaOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (6): RobertaLayer(\n",
            "          (attention): RobertaAttention(\n",
            "            (self): RobertaSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): RobertaSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): RobertaIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            (intermediate_act_fn): GELUActivation()\n",
            "          )\n",
            "          (output): RobertaOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (7): RobertaLayer(\n",
            "          (attention): RobertaAttention(\n",
            "            (self): RobertaSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): RobertaSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): RobertaIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            (intermediate_act_fn): GELUActivation()\n",
            "          )\n",
            "          (output): RobertaOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (8): RobertaLayer(\n",
            "          (attention): RobertaAttention(\n",
            "            (self): RobertaSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): RobertaSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): RobertaIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            (intermediate_act_fn): GELUActivation()\n",
            "          )\n",
            "          (output): RobertaOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (9): RobertaLayer(\n",
            "          (attention): RobertaAttention(\n",
            "            (self): RobertaSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): RobertaSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): RobertaIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            (intermediate_act_fn): GELUActivation()\n",
            "          )\n",
            "          (output): RobertaOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (10): RobertaLayer(\n",
            "          (attention): RobertaAttention(\n",
            "            (self): RobertaSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): RobertaSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): RobertaIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            (intermediate_act_fn): GELUActivation()\n",
            "          )\n",
            "          (output): RobertaOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (11): RobertaLayer(\n",
            "          (attention): RobertaAttention(\n",
            "            (self): RobertaSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): RobertaSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): RobertaIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            (intermediate_act_fn): GELUActivation()\n",
            "          )\n",
            "          (output): RobertaOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (classifier): RobertaClassificationHead(\n",
            "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "    (dropout): Dropout(p=0.1, inplace=False)\n",
            "    (out_proj): Linear(in_features=768, out_features=4, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "google.colab.output.setIframeHeight('300px');"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we train the model: (We first train the model with no class reweighting. This should give us good training accuracies but not as great generalization to the validation and test set.)"
      ],
      "metadata": {
        "id": "RsvVAjU-GI9R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm.auto import tqdm\n",
        "from datasets import load_metric\n",
        "from torch.nn import CrossEntropyLoss\n",
        "import random\n",
        "\n",
        "progress_bar = tqdm(range(num_training_steps))\n",
        "\n",
        "from transformers import AutoModelForSequenceClassification, Trainer\n",
        "\n",
        "row_format =\"{:<10} {:<20} {:<15} {:<20} {:<15}\"\n",
        "print(row_format.format(\"\", \"Approx. train loss\", \"Val loss\", \"Approx. train acc\", \"Val acc\"))\n",
        "\n",
        "# Train Model\n",
        "model.train()\n",
        "for epoch in range(num_epochs):\n",
        "    num_batches = 0\n",
        "    for batch in train_dataloader:\n",
        "        batch = {k: v.to(device) for k, v in batch.items()}\n",
        "        outputs = model(**batch)\n",
        "        loss = outputs.loss\n",
        "        loss.backward()\n",
        "\n",
        "        optimizer.step()\n",
        "        lr_scheduler.step()\n",
        "        optimizer.zero_grad()\n",
        "        progress_bar.update(1)\n",
        "        num_batches+=1\n",
        "\n",
        "        # Every 200 batches (1600 samples) print metrics\n",
        "        if num_batches%200 == 0:\n",
        "            model.eval()\n",
        "\n",
        "            with torch.no_grad():\n",
        "                metric1_train = load_metric(\"accuracy\")\n",
        "                metric1_val = load_metric(\"accuracy\")\n",
        "                #metric2 = load_metric(\"f1\")\n",
        "\n",
        "                # compute train loss\n",
        "                train_loss = 0\n",
        "                rand_loss_iters = set(random.sample(range(len(train_dataloader)), len(train_dataloader)//10)) # eval 0.1 of training set for approx.\n",
        "                count = -1\n",
        "                for batch in train_dataloader:\n",
        "                    count += 1\n",
        "                    if count not in rand_loss_iters: continue\n",
        "                    batch = {k: v.to(device) for k, v in batch.items()}\n",
        "\n",
        "                    outputs = model(**batch)\n",
        "                    train_loss += outputs.loss/len(rand_loss_iters)\n",
        "\n",
        "                    predictions = torch.argmax(outputs.logits, dim=-1)\n",
        "                    metric1_train.add_batch(predictions=predictions, references=batch[\"labels\"])\n",
        "\n",
        "                # compute val loss and metrics\n",
        "                val_loss = 0\n",
        "                for batch in val_dataloader:\n",
        "                    batch = {k: v.to(device) for k, v in batch.items()}\n",
        "\n",
        "                    outputs = model(**batch)\n",
        "                    val_loss += outputs.loss/len(val_dataloader)\n",
        "\n",
        "                    logits = outputs.logits\n",
        "                    predictions = torch.argmax(logits, dim=-1)\n",
        "                    metric1_val.add_batch(predictions=predictions, references=batch[\"labels\"])\n",
        "\n",
        "                print(row_format.format(f\"Step {num_batches}\", f\"{train_loss:.6f}\", f\"{val_loss:.6f}\", f\"{metric1_train.compute()['accuracy']:.6f}\", f\"{metric1_val.compute()['accuracy']:.6f}\"))\n",
        "            model.train()\n",
        "\n",
        "#torch.save(model.state_dict(), PATH_if_colab_or_not)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "305f0e5f47364df9a3090f984e81f25f",
            "88e4de8ab59e4209b408d9d101b4d7c9",
            "d473f6645b874da5921ed8846fb2ad60",
            "511b00eb57c04733bd4ab47a9caf533c",
            "0b7f8bd2333b42a1bf142a0b4ac9603a",
            "6fd967b209af4b60a2e6babd0018d2c0",
            "630dc44e618d4e0abae0c97f521c7214",
            "d26f49db38d3479ea312f7dd687f32b8",
            "8b177e4ef5354ce2a15859798f7427fe",
            "389cf0dc692549579bce4bb08c32c085",
            "5b66ea9f47714b08b8bed5ba9933a617"
          ]
        },
        "id": "pErO2qwNA0he",
        "outputId": "5e3683a3-d989-4552-d401-8e4ea66b6ec2"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/12260 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "305f0e5f47364df9a3090f984e81f25f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "           Approx. train loss   Val loss        Approx. train acc    Val acc        \n",
            "Step 200   0.795227             0.798312        0.649590             0.670511       \n",
            "Step 400   0.810914             0.787706        0.646516             0.664745       \n",
            "Step 600   0.849897             0.833256        0.588115             0.641680       \n",
            "Step 800   0.777563             0.814706        0.655738             0.664745       \n",
            "Step 1000  0.844570             0.828513        0.593238             0.642504       \n",
            "Step 1200  0.910838             0.974191        0.549180             0.518122       \n",
            "Step 200   0.884121             0.848163        0.627049             0.654036       \n",
            "Step 400   0.823827             0.838586        0.637860             0.636738       \n",
            "Step 600   0.758349             0.795792        0.688525             0.670511       \n",
            "Step 800   0.762162             0.746002        0.645492             0.675453       \n",
            "Step 1000  0.706068             0.740307        0.725309             0.707578       \n",
            "Step 1200  0.709749             0.733433        0.720287             0.700988       \n",
            "Step 200   0.722423             0.705647        0.686475             0.709226       \n",
            "Step 400   0.713957             0.752848        0.687500             0.676277       \n",
            "Step 600   0.751546             0.739702        0.674180             0.679572       \n",
            "Step 800   0.617129             0.666778        0.745902             0.710873       \n",
            "Step 1000  0.682136             0.707223        0.698770             0.677100       \n",
            "Step 1200  0.605263             0.685133        0.755123             0.677924       \n",
            "Step 200   0.681935             0.725233        0.740779             0.714992       \n",
            "Step 400   0.638248             0.659091        0.721311             0.729819       \n",
            "Step 600   0.766078             0.716597        0.656762             0.700988       \n",
            "Step 800   0.685205             0.690440        0.697746             0.716639       \n",
            "Step 1000  0.583770             0.676904        0.772541             0.706755       \n",
            "Step 1200  0.577171             0.661911        0.775720             0.726524       \n",
            "Step 200   0.588955             0.667923        0.764344             0.713344       \n",
            "Step 400   0.537778             0.623376        0.792008             0.740527       \n",
            "Step 600   0.543077             0.636231        0.789959             0.747117       \n",
            "Step 800   0.497482             0.717152        0.798156             0.724876       \n",
            "Step 1000  0.526732             0.678317        0.811475             0.724876       \n",
            "Step 1200  0.491427             0.630626        0.819672             0.734761       \n",
            "Step 200   0.463530             0.661463        0.829918             0.729819       \n",
            "Step 400   0.502015             0.697996        0.790984             0.733937       \n",
            "Step 600   0.408293             0.718886        0.848361             0.734761       \n",
            "Step 800   0.415426             0.731039        0.847336             0.734761       \n",
            "Step 1000  0.425382             0.714137        0.815574             0.733114       \n",
            "Step 1200  0.416232             0.629685        0.840164             0.751236       \n",
            "Step 200   0.358193             0.727541        0.855533             0.733937       \n",
            "Step 400   0.351653             0.721734        0.875000             0.747941       \n",
            "Step 600   0.302805             0.697799        0.884221             0.733114       \n",
            "Step 800   0.282438             0.709014        0.895492             0.741351       \n",
            "Step 1000  0.292346             0.691029        0.894467             0.749588       \n",
            "Step 1200  0.253821             0.685725        0.915984             0.741351       \n",
            "Step 200   0.333468             0.847020        0.888320             0.730643       \n",
            "Step 400   0.229802             0.848066        0.925926             0.726524       \n",
            "Step 600   0.206974             0.846910        0.922131             0.738056       \n",
            "Step 800   0.215501             0.796154        0.936475             0.742998       \n",
            "Step 1000  0.193988             0.855770        0.947746             0.739703       \n",
            "Step 1200  0.182597             0.923378        0.939549             0.743822       \n",
            "Step 200   0.122416             0.915944        0.956967             0.744646       \n",
            "Step 400   0.155919             0.974719        0.950617             0.734761       \n",
            "Step 600   0.153668             0.930655        0.956967             0.746293       \n",
            "Step 800   0.152126             0.976494        0.952869             0.731466       \n",
            "Step 1000  0.127738             0.981675        0.967213             0.738056       \n",
            "Step 1200  0.106074             0.930464        0.967213             0.739703       \n",
            "Step 200   0.099669             0.993212        0.967213             0.741351       \n",
            "Step 400   0.090947             0.987062        0.968238             0.738056       \n",
            "Step 600   0.090576             0.995839        0.972336             0.742175       \n",
            "Step 800   0.079664             1.027400        0.977459             0.734761       \n",
            "Step 1000  0.107480             1.038390        0.970287             0.742175       \n",
            "Step 1200  0.077170             1.039059        0.979508             0.738880       \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As we can see our model starts overfitting the training set, achieving near 98% accuracy, but due to our decreasing learning rates sees a nice plateauing of the validation accuracies. We get a humbly moderate validation accuracy of around 74%. Due to time constraints with training the transformer, I could not test more settings, but my first bet would be to perhaps set the learning rate scheduler to be exponential step function. Then, I would try decreasing the complexity of the model by encouraging more drop out in the final layers of RoBERTa. A final strategy could be to encode both sentences separately so that we can get a max sequence length of 1024, and inputting both encodings into another neural network.\n",
        "\n",
        "Here we calculate the test accuracy and f1 scores:"
      ],
      "metadata": {
        "id": "sFCSwg1OCyfm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "metric_acc = load_metric(\"accuracy\")\n",
        "metric_false_f1 = load_metric(\"f1\")\n",
        "metric_mixture_f1 = load_metric(\"f1\")\n",
        "metric_true_f1 = load_metric(\"f1\")\n",
        "metric_unproven_f1 = load_metric(\"f1\")\n",
        "model.eval()\n",
        "\n",
        "progress_bar = tqdm(range(len(test_dataloader)))\n",
        "\n",
        "# compute metrics for the test set\n",
        "for batch in test_dataloader:\n",
        "    batch = {k: v.to(device) for k, v in batch.items()}\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**batch)\n",
        "\n",
        "        logits = outputs.logits\n",
        "        predictions = torch.argmax(logits, dim=-1)\n",
        "        metric_acc.add_batch(predictions=predictions, references=batch[\"labels\"])\n",
        "        metric_false_f1.add_batch(predictions=(predictions == 0), references=(batch[\"labels\"] == 0))\n",
        "        metric_mixture_f1.add_batch(predictions=(predictions == 1), references=(batch[\"labels\"] == 1))\n",
        "        metric_true_f1.add_batch(predictions=(predictions == 2), references=(batch[\"labels\"] == 2))\n",
        "        metric_unproven_f1.add_batch(predictions=(predictions == 3), references=(batch[\"labels\"] == 3))\n",
        "    progress_bar.update(1)\n",
        "\n",
        "for metric in [\"metric_acc\", \"metric_false_f1\", \"metric_mixture_f1\", \"metric_true_f1\", \"metric_unproven_f1\"]:\n",
        "    metric_dict = globals()[metric].compute()\n",
        "    print(f\"{metric[7:]}: {metric_dict[list(metric_dict.keys())[0]]:.6f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136,
          "referenced_widgets": [
            "b61110fde821414ab2a7e7006bb79af5",
            "a457180b6f794b05b82ac4eee08b6266",
            "b6eac0380a1642d6a1155e2049afaf65",
            "486d05a3393c441e93812e9df66426bc",
            "e4d360fd240e4787ad9564f2bb534266",
            "8ab924dcc54c4de3bd15c4a01e37a8bd",
            "01af59788ee54e7bbfc125f7855b95ac",
            "b12cf33319dc4bc7b768eaf8b918700b",
            "5537434fa14c43c6be9bb6d102071c8a",
            "39d17796f24047eaaecc3597f645ca05",
            "03248e314a1942a88c0d5c19c58b7c6d"
          ]
        },
        "id": "x_Qgn-vEC_Jh",
        "outputId": "57521316-cb8b-4b4c-8204-eeccfe6409df"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/155 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b61110fde821414ab2a7e7006bb79af5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "acc: 0.704785\n",
            "false_f1: 0.675159\n",
            "mixture_f1: 0.444444\n",
            "true_f1: 0.843561\n",
            "unproven_f1: 0.433735\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We get an acceptable accuracy of around 70%. Looking at the f1 scores, we see that we get the highest f1 for true claims, and the second highest accuracy for false claims. This is good as when we receive a useful or harmful claim, our model has a good chance of knowing the correctness of those claims. Our model is more ambiguous on mixed or unproven claims, though this makes sense due to adversarial nature of mixed claims and the class imbalance with unproven claims. Methods to counter this could be to do contradiction detection on the explanation, such as in this [paper](https://nlp.stanford.edu/pubs/contradiction-acl08.pdf), and to introduce some reweighting of examples as I have set the bare bones of below."
      ],
      "metadata": {
        "id": "q_3GOx7QlPYR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# inverse_weight_tensor = torch.zeros(3)\n",
        "# for i in range(4): inverse_weight_tensor[i] = 1/label_dict[i]\n",
        "# inverse_weight_tensor = inverse_weight_tensor/torch.sum(inverse_weight_tensor)*3\n",
        "\n",
        "# sqrt_weight_tensor = torch.zeros(3)\n",
        "# for i in range(4): sqrt_weight_tensor[i] = 1/(label_dict[i]**0.5)\n",
        "# sqrt_weight_tensor = sqrt_weight_tensor/torch.sum(sqrt_weight_tensor)*3\n",
        "\n",
        "# When calculating loss:\n",
        "    # loss_reweight = torch.Tensor([inverse_weight_tensor[label] for label in batch[\"labels\"]]).to(device)\n",
        "    # batch = {k: v.to(device) for k, v in batch.items()}\n",
        "    # outputs = model(**batch)\n",
        "    # logits = outputs.logits\n",
        "    # loss_fct = CrossEntropyLoss(weight=loss_reweight)\n",
        "    # loss = loss_fct(logits, batch[\"labels\"])\n",
        "    # loss.backward()"
      ],
      "metadata": {
        "id": "sBF0sc-gOeav"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}